{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating the Future: GPT Robotic Process Automation Revolutionizes Journal Page Self-Publishing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Waves\" and \"Vectors\" \n",
    "are the names of my two journals in this collection. What they collect is ideas, decodings of my neurons. Mostly about waves and vectors as well as semantics and conscious experience and quantum entanglement. It is all pretty esoteric and just for fun. Some of them make me laugh. As does the idea that Journal Page Self-Publishing is even a thing.\n",
    "\n",
    "But you might say this is a self-published e-book.\n",
    "This automation project is intended to result in a kind of web publication of easily shared pages.    \n",
    "\n",
    "Using GPT on the OpenAI API I'm automating o_o \n",
    "\n",
    "- Generation of a title, a summary, and a full description of each image.\n",
    "- Then a viewable page is generated, integrating the original image and the text into a share-able, \"published\", document.\n",
    "\n",
    "- After publishing enough (12-60) pages. I plan to automate the collection of documents, organized by subtle sentiment in a table of contents with a concept index and thumbnails.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install if needed\n",
    "%pip install openai requests markdownify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be documenting the workflow for generating titles, summaries, and detailed explanations for journal pages using the ChatGPT model. The code provided below demonstrates how we iterate through each journal and its pages, generate prompts, and obtain responses from the ChatGPT model. The resulting content is then saved in separate Markdown files for each journal page. This workflow allows us to automate the generation of descriptive content for our journal collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: waves_8\n",
      "https://github.com/antfriend/journals/blob/main/waves/waves_8.png?raw=true\n",
      "processing: waves_88\n",
      "https://github.com/antfriend/journals/blob/main/waves/waves_88.png?raw=true\n",
      "processing: waves_107\n",
      "https://github.com/antfriend/journals/blob/main/waves/waves_107.png?raw=true\n",
      "processing: vectors_2\n",
      "https://github.com/antfriend/journals/blob/main/vectors/vectors_2.png?raw=true\n",
      "processing: vectors_6\n",
      "https://github.com/antfriend/journals/blob/main/vectors/vectors_6.png?raw=true\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "journals = {\n",
    "    'waves': ['8','88','107'],\n",
    "    'vectors': ['2','6']\n",
    "}\n",
    "\n",
    "prompt = (\"Analyze the content and meaning of this journal page. \" \n",
    "          \"Generate an appropriate and catchy title. \"\n",
    "          \"As a scientist with a sense of humor, write a summary \"\n",
    "          \"of the meaning in two sentences or less. \"\n",
    "          \"Finally, as a scientist, write a detailed explanation, \"\n",
    "          \"using well-formed sentences and correct grammar.\")\n",
    "client = OpenAI()\n",
    "\n",
    "# Iterating through each journal and its pages\n",
    "for journal, pages in journals.items():\n",
    "    for page_number in pages:\n",
    "        journal_image_name = journal + \"_\" + page_number\n",
    "        image_url = \"https://github.com/antfriend/journals/blob/main/\" + journal + \"/\" + journal_image_name + \".png?raw=true\"\n",
    "        print('processing: ' + journal_image_name)\n",
    "        print(image_url)\n",
    "\n",
    "        # Generating the response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": prompt},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": image_url}}\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "\n",
    "        message_content = 'image_url: ' + image_url + \"\\n\\n\" + response.choices[0].message.content\n",
    "        filename = journal_image_name + \".md\"\n",
    "\n",
    "        # Writing to the file\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(message_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge md and png files into a single html file\n",
    "#%pip install markdownify    \n",
    "import markdownify\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "for journal, pages in journals.items():\n",
    "    for page_number in pages:\n",
    "        journal_image_name = journal + \"_\" + page_number\n",
    "        image_url = \"<img src=\\\"\" + journal_image_name + \".png\\\" alt=\\\"\" + journal_image_name + \"\\\" width=\\\"1000\\\" height=\\\"1000\\\">\\n\"   \n",
    "        filename = journal_image_name + \".md\"\n",
    "\n",
    "        # Writing to the file\n",
    "        with open(filename, 'r') as file:\n",
    "            file_content = file.read()\n",
    "            file_content = file_content.replace(\"image_url: \" + image_url, image_url)\n",
    "            html_content = markdownify.markdownify(file_content)\n",
    "            html_content = html_content.replace(\"<img src=\\\"\", \"<img src=\\\"\" + journal + \"/\")\n",
    "            html_content = html_content.replace(\"<img src=\\\"http\", \"<img src=\\\"https\")\n",
    "            html_content = html_content.replace(\"<img src=\\\"/\", \"<img src=\\\"    /\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
