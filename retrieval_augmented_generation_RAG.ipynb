{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "Building the Journal page navigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install python-dotenv\n",
    "%pip install lark\n",
    "%pip install chromadb\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "## Initialize OpenAI API\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "print('ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 journal pages from:\n",
      "https://antfriend.github.io/journals/waves_15.html\n",
      "to:\n",
      "https://antfriend.github.io/journals/vectors_32.html\n",
      "13 documents loaded\n",
      "[Document(page_content='\\n\\n\\n\\n\\n\\nTitle: \"Entangled Minds: Quantum Observations in the Stardust\" journal page\\n\\n\\n\\nJournals Home \\n\\n\\n\\n\\n\\n\"Entangled Minds: Quantum Observations in the Stardust\"\\nScientist with a sense of humor summary:\\nOur brains are like glow-in-the-dark toys, and by peeking at the stars, we might just be playing cosmic tag with light from eons ago.\\nFourth grader summary:\\nImagine your brain lighting up like a firefly when you look at stars â€” it\\'s like making friends with light from way back in the past!\\nDetailed scientific explanation:\\nThe journal page appears to express a poetic and metaphorical connection between human observation and the universe through the lens of quantum physics. The writer suggests that by looking at a star, there is an instantaneous, albeit metaphysical, link created between the observer and the celestial body, which is reminiscent of quantum entanglement. Quantum entanglement is a phenomenon wherein two particles, regardless of the distance separating them, are intimately linked in such a way that the state of one instantaneously influences the state of the other.\\nThe journal references that in 2023, \"bioluminescent neurons\" were discovered in our brains, suggesting that there\\'s a literal illumination within the mind during the observation process. This is a metaphor for the light of understanding or the \\'aha\\' moment that occurs when we make sense of something, not actual bioluminescent neurons which, to the best of existing scientific knowledge, are not a characteristic of the human brain. The author metaphorically proposes that our brains are like quantum computers, capable of holding vast amounts of entangled data.\\nFurthermore, the journal invokes the Cosmic Bell Experiments, which test quantum entanglement principles over large distances. By likening these experiments to the act of observation, the author playfully suggests that just as particles may remain entangled over cosmic scales, so too our observations might imprint upon or interconnect with the cosmos, echoing a sentiment of unity with the universe. This aligns with philosophical and speculative interpretations of quantum mechanics, where observation plays a crucial role in the behavior of particles.\\nHowever, while the musings are imaginative and capture the wonder of the universe, and the interconnectedness suggested by quantum phenomena, they\\'re not reflective of literal scientific truth. Current scientific understanding does not support the notion that human observation causes literal entanglement with distant stars or that our memories are stored anywhere outside our biological brain in a quantum state.\\n\\n\\n\\n\\n', metadata={'source': 'https://antfriend.github.io/journals/waves_15.html', 'title': 'Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page', 'language': 'No language found.'})] ...\n"
     ]
    }
   ],
   "source": [
    "## Document Loading\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://antfriend.github.io/journals\"\n",
    "\n",
    "# Function to get all HTML document URLs from the base URL\n",
    "def get_document_urls(base_url):\n",
    "    page = requests.get(base_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    # Check if href is not None and ends with '.html'\n",
    "    # An anchor tag with an href of None is a link to the current page\n",
    "    document_urls = [link.get('href') for link in links if link.get('href') and link.get('href').endswith('.html')]\n",
    "    document_urls = [base_url + '/' + url for url in document_urls]\n",
    "    return document_urls\n",
    "\n",
    "# Get all document URLs\n",
    "document_urls = get_document_urls(base_url)\n",
    "print(len(document_urls), 'journal pages from:')\n",
    "print(document_urls[0])\n",
    "print('to:')\n",
    "print(document_urls[-1])\n",
    "\n",
    "# Load and process each document\n",
    "documents = []\n",
    "for url in document_urls:\n",
    "    # Initialize the WebBaseLoader\n",
    "    loader = WebBaseLoader(url)\n",
    "    document = loader.load()\n",
    "    documents.append(document)\n",
    "\n",
    "# `documents` now contains the loaded HTML content from each URL\n",
    "print(len(documents), 'documents loaded')\n",
    "print(documents[0][:100], '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 documents split\n",
      "into a total of 41 splits\n",
      "each split resembles: page_content='Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page\\n\\n\\n\\nJournals Home' metadata={'source': 'https://antfriend.github.io/journals/waves_15.html', 'title': 'Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page', 'language': 'No language found.'}\n",
      " \n",
      "13 documents embedded\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits_collection = []\n",
    "for doc in documents:\n",
    "    try:\n",
    "        splits = text_splitter.split_documents(doc)\n",
    "        splits_collection.append(splits)\n",
    "        #print(len(splits), 'documents split')\n",
    "        #print(splits[0])\n",
    "    except:\n",
    "        print('Error splitting documents')\n",
    "        print('Try reducing chunk_size and chunk_overlap')\n",
    "        raise\n",
    "print(len(splits_collection), 'documents split')\n",
    "print('into a total of', sum([len(splits) for splits in splits_collection]), 'splits')\n",
    "print('each split resembles:', splits_collection[0][0])\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "embeddings.embed_documents\n",
    "embeddings_collection_of_collections = []\n",
    "embeddings_collection = []\n",
    "\n",
    "for splits in splits_collection:\n",
    "    #print(' ')\n",
    "    # Generating embeddings for each split\n",
    "    for split in splits:\n",
    "        # print(split.page_content[:100], '...')\n",
    "        embed = embeddings.embed_documents(split.page_content)\n",
    "        embeddings_collection.append(embed)\n",
    "\n",
    "    # `embeddings_collection` now contains the embeddings for each split\n",
    "    embeddings_collection_of_collections.append(embeddings_collection)\n",
    "print(' ')\n",
    "print(len(embeddings_collection_of_collections), 'documents embedded') # 1 per document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings on splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.003934556732305011,\n",
       " -0.014521354298720337,\n",
       " 0.013507292997201745,\n",
       " -0.005266356900147807,\n",
       " -0.028583000310713525,\n",
       " 0.008213894679655383,\n",
       " -0.020389387974675634,\n",
       " -0.01650891314584513,\n",
       " -0.005790288727819512,\n",
       " -0.018077327462155166]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(' ')\n",
    "embeddings_collection_of_collections[0][0][0][:10] # 1 per split\n",
    "# embedding1 = embedding.embed_query(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storage\n",
    "from langchain.vectorstores import Chroma\n",
    "#from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings_collection_of_collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# embedding = OpenAIEmbeddings()\n",
    "# vectordb = Chroma(\n",
    "#     persist_directory=persist_directory,\n",
    "#     embedding_function=embedding\n",
    "# )\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
