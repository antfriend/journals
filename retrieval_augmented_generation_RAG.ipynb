{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "Building the Journal page navigator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain\n",
    "%pip install python-dotenv\n",
    "%pip install lark\n",
    "%pip install chromadb\n",
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "## Initialize OpenAI API\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
    "print('ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 journal pages from:\n",
      "https://antfriend.github.io/journals/waves_15.html\n",
      "to:\n",
      "https://antfriend.github.io/journals/vectors_32.html\n",
      "13 documents loaded\n",
      "[Document(page_content='\\n\\n\\n\\n\\n\\nTitle: \"Entangled Minds: Quantum Observations in the Stardust\" journal page\\n\\n\\n\\nJournals Home \\n\\n\\n\\n\\n\\n\"Entangled Minds: Quantum Observations in the Stardust\"\\nScientist with a sense of humor summary:\\nOur brains are like glow-in-the-dark toys, and by peeking at the stars, we might just be playing cosmic tag with light from eons ago.\\nFourth grader summary:\\nImagine your brain lighting up like a firefly when you look at stars â€” it\\'s like making friends with light from way back in the past!\\nDetailed scientific explanation:\\nThe journal page appears to express a poetic and metaphorical connection between human observation and the universe through the lens of quantum physics. The writer suggests that by looking at a star, there is an instantaneous, albeit metaphysical, link created between the observer and the celestial body, which is reminiscent of quantum entanglement. Quantum entanglement is a phenomenon wherein two particles, regardless of the distance separating them, are intimately linked in such a way that the state of one instantaneously influences the state of the other.\\nThe journal references that in 2023, \"bioluminescent neurons\" were discovered in our brains, suggesting that there\\'s a literal illumination within the mind during the observation process. This is a metaphor for the light of understanding or the \\'aha\\' moment that occurs when we make sense of something, not actual bioluminescent neurons which, to the best of existing scientific knowledge, are not a characteristic of the human brain. The author metaphorically proposes that our brains are like quantum computers, capable of holding vast amounts of entangled data.\\nFurthermore, the journal invokes the Cosmic Bell Experiments, which test quantum entanglement principles over large distances. By likening these experiments to the act of observation, the author playfully suggests that just as particles may remain entangled over cosmic scales, so too our observations might imprint upon or interconnect with the cosmos, echoing a sentiment of unity with the universe. This aligns with philosophical and speculative interpretations of quantum mechanics, where observation plays a crucial role in the behavior of particles.\\nHowever, while the musings are imaginative and capture the wonder of the universe, and the interconnectedness suggested by quantum phenomena, they\\'re not reflective of literal scientific truth. Current scientific understanding does not support the notion that human observation causes literal entanglement with distant stars or that our memories are stored anywhere outside our biological brain in a quantum state.\\n\\n\\n\\n\\n', metadata={'source': 'https://antfriend.github.io/journals/waves_15.html', 'title': 'Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page', 'language': 'No language found.'})] ...\n"
     ]
    }
   ],
   "source": [
    "## Document Loading\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the base URL\n",
    "base_url = \"https://antfriend.github.io/journals\"\n",
    "\n",
    "# Function to get all HTML document URLs from the base URL\n",
    "def get_document_urls(base_url):\n",
    "    page = requests.get(base_url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "\n",
    "    # Check if href is not None and ends with '.html'\n",
    "    # An anchor tag with an href of None is a link to the current page\n",
    "    document_urls = [link.get('href') for link in links if link.get('href') and link.get('href').endswith('.html')]\n",
    "    document_urls = [base_url + '/' + url for url in document_urls]\n",
    "    return document_urls\n",
    "\n",
    "# Get all document URLs\n",
    "document_urls = get_document_urls(base_url)\n",
    "print(len(document_urls), 'journal pages from:')\n",
    "print(document_urls[0])\n",
    "print('to:')\n",
    "print(document_urls[-1])\n",
    "\n",
    "# Load and process each document\n",
    "documents = []\n",
    "for url in document_urls:\n",
    "    # Initialize the WebBaseLoader\n",
    "    loader = WebBaseLoader(url)\n",
    "    document = loader.load()\n",
    "    documents.append(document)\n",
    "\n",
    "# `documents` now contains the loaded HTML content from each URL\n",
    "print(len(documents), 'documents loaded')\n",
    "print(documents[0][:100], '...')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 documents split\n",
      "into a total of 56 splits\n",
      "each split resembles: page_content='Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page\\n\\n\\n\\nJournals Home' metadata={'source': 'https://antfriend.github.io/journals/waves_15.html', 'title': 'Title: \"Entangled Minds: Quantum Observations in the Stardust\" journal page', 'language': 'No language found.'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m embeddings_collection \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m splits \u001b[38;5;129;01min\u001b[39;00m splits_collection:\n\u001b[1;32m---> 26\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     embeddings_collection\u001b[38;5;241m.\u001b[39mappend(embeddings)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(embeddings_collection), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments embedded\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# 1 per document\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\embeddings\\openai.py:669\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_len_safe_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\langchain\\embeddings\\openai.py:472\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m001\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# See: https://github.com/openai/openai-python/\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m#      issues/418#issuecomment-1525939500\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;66;03m# replace newlines, which can negatively affect performance.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 472\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[43mencoding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_special\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallowed_special\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisallowed_special\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisallowed_special\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# Split tokens into chunks respecting the embedding_ctx_length\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(token), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ctx_length):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tiktoken\\core.py:116\u001b[0m, in \u001b[0;36mEncoding.encode\u001b[1;34m(self, text, allowed_special, disallowed_special)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(disallowed_special, \u001b[38;5;28mfrozenset\u001b[39m):\n\u001b[0;32m    115\u001b[0m         disallowed_special \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m(disallowed_special)\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m match \u001b[38;5;241m:=\u001b[39m \u001b[43m_special_token_regex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisallowed_special\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    117\u001b[0m         raise_disallowed_special_token(match\u001b[38;5;241m.\u001b[39mgroup())\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 999,\n",
    "    chunk_overlap = 99\n",
    ")\n",
    "splits_collection = []\n",
    "for doc in documents:\n",
    "    try:\n",
    "        splits = text_splitter.split_documents(doc)\n",
    "        splits_collection.append(splits)\n",
    "        #print(len(splits), 'documents split')\n",
    "        #print(splits[0])\n",
    "    except:\n",
    "        print('Error splitting documents')\n",
    "        print('Try reducing chunk_size and chunk_overlap')\n",
    "        raise\n",
    "print(len(splits_collection), 'documents split')\n",
    "print('into a total of', sum([len(splits) for splits in splits_collection]), 'splits')\n",
    "print('each split resembles:', splits_collection[0][0])\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "embeddings_collection = []\n",
    "for splits in splits_collection:\n",
    "    embeddings = embedding.embed_documents(splits)\n",
    "    embeddings_collection.append(embeddings)\n",
    "print(len(embeddings_collection), 'documents embedded') # 1 per document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embeddings on splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embedding1 = embedding.embed_query(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Storage\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Retrieval\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
